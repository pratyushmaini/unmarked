{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8af4ab9a-a26c-4f4c-aab8-9b4e6a60c779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/unmarked/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import yaml\n",
    "import os\n",
    "import logging\n",
    "import shutil\n",
    "import numpy as np\n",
    "from PIL import Image \n",
    "logger = logging.getLogger()\n",
    "handler = logging.StreamHandler()\n",
    "handler.setLevel(logging.INFO)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from diffusers import DDIMScheduler, EulerDiscreteScheduler\n",
    "from datasets import load_dataset\n",
    "from diffusers.utils.torch_utils import randn_tensor\n",
    "from huggingface_hub import hf_hub_download\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "from main.wmdiffusionxl import WMDetectStableDiffusionXLPipeline\n",
    "from main.wmpatch import GTWatermark, GTWatermarkMulti\n",
    "from main.utils import *\n",
    "from loss.loss import LossProvider\n",
    "from loss.pytorch_ssim import ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2748227d-8820-40f5-a794-014d62e3652c",
   "metadata": {},
   "source": [
    "## Necessary Setup for All Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9708dfcc-8389-42cd-bd52-261809b338c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "===== Load Config =====\n",
      "{'method': 'ZoDiac', 'save_img': './example/output/', 'model_id': 'stabilityai/stable-diffusion-2-1-base', 'gen_seed': 0, 'empty_prompt': True, 'w_type': 'single', 'w_channel': 3, 'w_radius': 10, 'w_seed': 10, 'start_latents': 'init_w', 'iters': 100, 'save_iters': [100], 'loss_weights': [10.0, 0.1, 1.0, 0.0], 'ssim_threshold': 0.92, 'detect_threshold': 0.9}\n"
     ]
    }
   ],
   "source": [
    "logging.info(f'===== Load Config =====')\n",
    "device = torch.device('cuda')\n",
    "with open('./example/config/config.yaml', 'r') as file:\n",
    "    cfgs = yaml.safe_load(file)\n",
    "logging.info(cfgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accc6ac2-9055-4237-877e-9276f91da074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "===== Init Pipeline =====\n"
     ]
    }
   ],
   "source": [
    "logging.info(f'===== Init Pipeline =====')\n",
    "if cfgs['w_type'] == 'single':\n",
    "    wm_pipe = GTWatermark(device, w_channel=cfgs['w_channel'], w_radius=cfgs['w_radius'], generator=torch.Generator(device).manual_seed(cfgs['w_seed']))\n",
    "elif cfgs['w_type'] == 'multi':\n",
    "    wm_pipe = GTWatermarkMulti(device, w_settings=cfgs['w_settings'], generator=torch.Generator(device).manual_seed(cfgs['w_seed']))\n",
    "\n",
    "# scheduler = DDIMScheduler.from_pretrained(cfgs['model_id'], subfolder=\"scheduler\")\n",
    "# pipe = WMDetectStableDiffusionPipeline.from_pretrained(cfgs['model_id'], scheduler=scheduler).to(device)\n",
    "# pipe.set_progress_bar_config(disable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12cdb68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/unmarked/lib/python3.12/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  7.03it/s]\n",
      "/opt/conda/envs/unmarked/lib/python3.12/site-packages/diffusers/configuration_utils.py:134: FutureWarning: Accessing config attribute `force_zeros_for_empty_prompt` directly via 'WMDetectStableDiffusionXLPipeline' object attribute is deprecated. Please access 'force_zeros_for_empty_prompt' over 'WMDetectStableDiffusionXLPipeline's config object instead, e.g. 'scheduler.config.force_zeros_for_empty_prompt'.\n",
      "  deprecate(\"direct config name access\", \"1.0.0\", deprecation_message, standard_warn=False)\n"
     ]
    }
   ],
   "source": [
    "base = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "repo = \"ByteDance/SDXL-Lightning\"\n",
    "checkpoint = \"sdxl_lightning_4step_unet.safetensors\"\n",
    "device = 'cuda'\n",
    "\n",
    "pipe = WMDetectStableDiffusionXLPipeline.from_pretrained(\n",
    "    base,\n",
    "    torch_dtype=torch.float16,\n",
    "    variant=\"fp16\"\n",
    ").to(device)\n",
    "scheduler = EulerDiscreteScheduler.from_config(\n",
    "    pipe.scheduler.config,\n",
    "    timestep_spacing=\"trailing\",\n",
    "    prediction_type=\"epsilon\"\n",
    ")\n",
    "# scheduler = DDIMScheduler.from_pretrained(pipe.scheduler.config)\n",
    "pipe.scheduler = scheduler\n",
    "pipe.unet.load_state_dict(\n",
    "    load_file(\n",
    "        hf_hub_download(repo, checkpoint),\n",
    "        device=device\n",
    "    )\n",
    ")\n",
    "pipe.set_progress_bar_config(disable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f44fa9d0-13b2-4a76-a839-56720c73b9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagename = 'pepper.tiff'\n",
    "gt_img_tensor = get_img_tensor(f'./example/input/{imagename}', device)\n",
    "wm_path = cfgs['save_img']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420e6ef3-2834-488c-a438-c85bd4c6d7cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Image Watermarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef73c981-a5a2-46e1-9447-fb3dd718177e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2048) must match the size of tensor b (1024) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m reversed_latents\n\u001b[1;32m     14\u001b[0m empty_text_embeddings \u001b[38;5;241m=\u001b[39m pipe\u001b[38;5;241m.\u001b[39mget_text_embedding(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m init_latents_approx \u001b[38;5;241m=\u001b[39m \u001b[43mget_init_latent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgt_img_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mempty_text_embeddings\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m, in \u001b[0;36mget_init_latent\u001b[0;34m(img_tensor, pipe, text_embeddings, guidance_scale)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautocast(device_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16):\n\u001b[1;32m      5\u001b[0m     img_latents \u001b[38;5;241m=\u001b[39m pipe\u001b[38;5;241m.\u001b[39mget_image_latents(img_tensor, sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 6\u001b[0m     reversed_latents \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_diffusion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_latents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mguidance_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mguidance_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_inference_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reversed_latents\n",
      "File \u001b[0;32m/opt/conda/envs/unmarked/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ZoDiac/main/wmdiffusionxl.py:352\u001b[0m, in \u001b[0;36mWMDetectStableDiffusionXLPipeline.backward_diffusion\u001b[0;34m(self, use_old_emb_i, text_embeddings, old_text_embeddings, new_text_embeddings, latents, num_inference_steps, guidance_scale, callback, callback_steps, reverse_process, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m latent_model_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mscale_model_input(latent_model_input, t)\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munet\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39maddition_embed_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \n\u001b[0;32m--> 352\u001b[0m noise_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlatent_model_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcross_attention_kwargs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msample\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_classifier_free_guidance:\n\u001b[1;32m    360\u001b[0m     noise_pred_uncond, noise_pred_text \u001b[38;5;241m=\u001b[39m noise_pred\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/unmarked/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/unmarked/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/unmarked/lib/python3.12/site-packages/diffusers/models/unet_2d_condition.py:959\u001b[0m, in \u001b[0;36mUNet2DConditionModel.forward\u001b[0;34m(self, sample, timestep, encoder_hidden_states, class_labels, timestep_cond, attention_mask, cross_attention_kwargs, added_cond_kwargs, down_block_additional_residuals, mid_block_additional_residual, encoder_attention_mask, return_dict)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_adapter \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(down_block_additional_residuals) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    957\u001b[0m         additional_residuals[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madditional_residuals\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m down_block_additional_residuals\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 959\u001b[0m     sample, res_samples \u001b[38;5;241m=\u001b[39m \u001b[43mdownsample_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43memb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_residuals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    969\u001b[0m     sample, res_samples \u001b[38;5;241m=\u001b[39m downsample_block(hidden_states\u001b[38;5;241m=\u001b[39msample, temb\u001b[38;5;241m=\u001b[39memb, scale\u001b[38;5;241m=\u001b[39mlora_scale)\n",
      "File \u001b[0;32m/opt/conda/envs/unmarked/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/unmarked/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/unmarked/lib/python3.12/site-packages/diffusers/models/unet_2d_blocks.py:1086\u001b[0m, in \u001b[0;36mCrossAttnDownBlock2D.forward\u001b[0;34m(self, hidden_states, temb, encoder_hidden_states, attention_mask, cross_attention_kwargs, encoder_attention_mask, additional_residuals)\u001b[0m\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1085\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m resnet(hidden_states, temb, scale\u001b[38;5;241m=\u001b[39mlora_scale)\n\u001b[0;32m-> 1086\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;66;03m# apply additional residuals to the output of the last pair of resnet and attention blocks\u001b[39;00m\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(blocks) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m additional_residuals \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/unmarked/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/unmarked/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/unmarked/lib/python3.12/site-packages/diffusers/models/transformer_2d.py:315\u001b[0m, in \u001b[0;36mTransformer2DModel.forward\u001b[0;34m(self, hidden_states, encoder_hidden_states, timestep, class_labels, cross_attention_kwargs, attention_mask, encoder_attention_mask, return_dict)\u001b[0m\n\u001b[1;32m    303\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    304\u001b[0m             block,\n\u001b[1;32m    305\u001b[0m             hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    312\u001b[0m             use_reentrant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    313\u001b[0m         )\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 315\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimestep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m            \u001b[49m\u001b[43mclass_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# 3. Output\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_input_continuous:\n",
      "File \u001b[0;32m/opt/conda/envs/unmarked/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/unmarked/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/unmarked/lib/python3.12/site-packages/diffusers/models/attention.py:224\u001b[0m, in \u001b[0;36mBasicTransformerBlock.forward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, timestep, cross_attention_kwargs, class_labels)\u001b[0m\n\u001b[1;32m    214\u001b[0m     norm_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(hidden_states, timestep) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_ada_layer_norm \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(hidden_states)\n\u001b[1;32m    216\u001b[0m     )\n\u001b[1;32m    218\u001b[0m     attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn2(\n\u001b[1;32m    219\u001b[0m         norm_hidden_states,\n\u001b[1;32m    220\u001b[0m         encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[1;32m    221\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mencoder_attention_mask,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcross_attention_kwargs,\n\u001b[1;32m    223\u001b[0m     )\n\u001b[0;32m--> 224\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mattn_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# 4. Feed-forward\u001b[39;00m\n\u001b[1;32m    227\u001b[0m norm_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm3(hidden_states)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2048) must match the size of tensor b (1024) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# Step 1: Get init noise\n",
    "def get_init_latent(img_tensor, pipe, text_embeddings, guidance_scale=1.0):\n",
    "    # DDIM inversion from the given image\n",
    "    with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "        img_latents = pipe.get_image_latents(img_tensor, sample=False)\n",
    "        reversed_latents = pipe.forward_diffusion(\n",
    "            latents=img_latents,\n",
    "            text_embeddings=text_embeddings,\n",
    "            guidance_scale=guidance_scale,\n",
    "            num_inference_steps=4,\n",
    "        )\n",
    "        return reversed_latents\n",
    "\n",
    "empty_text_embeddings = pipe.get_text_embedding('')\n",
    "init_latents_approx = get_init_latent(gt_img_tensor, pipe, empty_text_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "914c7cd2-65bc-40e3-8708-d32fdf8eb6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/unmarked/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/unmarked/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /home/ec2-user/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:01<00:00, 535MB/s] \n",
      "/home/ec2-user/ZoDiac/loss/loss.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loss_percep.load_state_dict(torch.load('./loss/rgb_watson_vgg_trial0.pth', map_location='cpu'))\n"
     ]
    }
   ],
   "source": [
    "# Step 2: prepare training\n",
    "init_latents = init_latents_approx.detach().clone()\n",
    "init_latents.requires_grad = True\n",
    "optimizer = optim.Adam([init_latents], lr=0.01)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30,80], gamma=0.3) \n",
    "\n",
    "totalLoss = LossProvider(cfgs['loss_weights'], device)\n",
    "loss_lst = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b6ab2f-eade-4819-8f7f-220d58930919",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter 0:\n",
      "/home/ec2-user/ZoDiac/main/wmdiffusion.py:198: FutureWarning: Accessing config attribute `in_channels` directly via 'UNet2DConditionModel' object attribute is deprecated. Please access 'in_channels' over 'UNet2DConditionModel's config object instead, e.g. 'unet.config.in_channels'.\n",
      "  num_channels_latents = self.unet.in_channels\n",
      "/opt/conda/envs/unmarked/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "Watermark 0.0000, Image 0.5736, Perp 0.9297, SSIM 0.5659 Total Loss 2.0692\n",
      "iter 1:\n",
      "Watermark 0.0000, Image 0.4470, Perp 0.8598, SSIM 0.5189 Total Loss 1.8257\n",
      "iter 2:\n",
      "Watermark 0.0000, Image 0.3810, Perp 0.8211, SSIM 0.4935 Total Loss 1.6955\n",
      "iter 3:\n",
      "Watermark 0.0000, Image 0.3406, Perp 0.7922, SSIM 0.4760 Total Loss 1.6088\n",
      "iter 4:\n",
      "Watermark 0.0000, Image 0.3156, Perp 0.7842, SSIM 0.4716 Total Loss 1.5714\n",
      "iter 5:\n",
      "Watermark 0.0000, Image 0.2764, Perp 0.7409, SSIM 0.4467 Total Loss 1.4640\n",
      "iter 6:\n",
      "Watermark 0.0000, Image 0.2539, Perp 0.7466, SSIM 0.4422 Total Loss 1.4427\n",
      "iter 7:\n",
      "Watermark 0.0000, Image 0.2271, Perp 0.7289, SSIM 0.4273 Total Loss 1.3832\n",
      "iter 8:\n",
      "Watermark 0.0000, Image 0.1995, Perp 0.6845, SSIM 0.4060 Total Loss 1.2900\n",
      "iter 9:\n",
      "Watermark 0.0000, Image 0.1791, Perp 0.6411, SSIM 0.3892 Total Loss 1.2094\n",
      "iter 10:\n",
      "Watermark 0.0000, Image 0.1676, Perp 0.6179, SSIM 0.3800 Total Loss 1.1655\n",
      "iter 11:\n",
      "Watermark 0.0000, Image 0.1595, Perp 0.6051, SSIM 0.3751 Total Loss 1.1397\n",
      "iter 12:\n",
      "Watermark 0.0000, Image 0.1514, Perp 0.5758, SSIM 0.3686 Total Loss 1.0958\n",
      "iter 13:\n",
      "Watermark 0.0000, Image 0.1448, Perp 0.5621, SSIM 0.3644 Total Loss 1.0713\n",
      "iter 14:\n",
      "Watermark 0.0000, Image 0.1395, Perp 0.5480, SSIM 0.3610 Total Loss 1.0485\n",
      "iter 15:\n",
      "Watermark 0.0000, Image 0.1359, Perp 0.5439, SSIM 0.3593 Total Loss 1.0391\n",
      "iter 16:\n",
      "Watermark 0.0000, Image 0.1329, Perp 0.5381, SSIM 0.3571 Total Loss 1.0281\n",
      "iter 17:\n",
      "Watermark 0.0000, Image 0.1301, Perp 0.5309, SSIM 0.3546 Total Loss 1.0157\n",
      "iter 18:\n",
      "Watermark 0.0000, Image 0.1277, Perp 0.5234, SSIM 0.3521 Total Loss 1.0032\n",
      "iter 19:\n",
      "Watermark 0.0000, Image 0.1254, Perp 0.5152, SSIM 0.3494 Total Loss 0.9901\n",
      "iter 20:\n",
      "Watermark 0.0000, Image 0.1232, Perp 0.5048, SSIM 0.3465 Total Loss 0.9746\n",
      "iter 21:\n",
      "Watermark 0.0000, Image 0.1216, Perp 0.4953, SSIM 0.3445 Total Loss 0.9614\n",
      "iter 22:\n",
      "Watermark 0.0000, Image 0.1205, Perp 0.4875, SSIM 0.3436 Total Loss 0.9516\n",
      "iter 23:\n",
      "Watermark 0.0000, Image 0.1194, Perp 0.4793, SSIM 0.3428 Total Loss 0.9415\n",
      "iter 24:\n",
      "Watermark 0.0000, Image 0.1185, Perp 0.4735, SSIM 0.3423 Total Loss 0.9342\n",
      "iter 25:\n",
      "Watermark 0.0000, Image 0.1174, Perp 0.4679, SSIM 0.3417 Total Loss 0.9270\n",
      "iter 26:\n",
      "Watermark 0.0000, Image 0.1165, Perp 0.4632, SSIM 0.3412 Total Loss 0.9208\n",
      "iter 27:\n",
      "Watermark 0.0000, Image 0.1155, Perp 0.4576, SSIM 0.3408 Total Loss 0.9139\n",
      "iter 28:\n",
      "Watermark 0.0000, Image 0.1148, Perp 0.4524, SSIM 0.3406 Total Loss 0.9078\n",
      "iter 29:\n",
      "Watermark 0.0000, Image 0.1145, Perp 0.4483, SSIM 0.3408 Total Loss 0.9036\n",
      "iter 30:\n",
      "Watermark 0.0000, Image 0.1145, Perp 0.4457, SSIM 0.3414 Total Loss 0.9016\n",
      "iter 31:\n",
      "Watermark 0.0000, Image 0.1145, Perp 0.4449, SSIM 0.3415 Total Loss 0.9009\n",
      "iter 32:\n",
      "Watermark 0.0000, Image 0.1145, Perp 0.4435, SSIM 0.3415 Total Loss 0.8996\n",
      "iter 33:\n",
      "Watermark 0.0000, Image 0.1144, Perp 0.4418, SSIM 0.3414 Total Loss 0.8976\n",
      "iter 34:\n",
      "Watermark 0.0000, Image 0.1143, Perp 0.4395, SSIM 0.3411 Total Loss 0.8949\n",
      "iter 35:\n",
      "Watermark 0.0000, Image 0.1141, Perp 0.4368, SSIM 0.3408 Total Loss 0.8917\n",
      "iter 36:\n",
      "Watermark 0.0000, Image 0.1138, Perp 0.4337, SSIM 0.3403 Total Loss 0.8877\n",
      "iter 37:\n",
      "Watermark 0.0000, Image 0.1134, Perp 0.4304, SSIM 0.3397 Total Loss 0.8835\n",
      "iter 38:\n",
      "Watermark 0.0000, Image 0.1131, Perp 0.4270, SSIM 0.3391 Total Loss 0.8792\n",
      "iter 39:\n",
      "Watermark 0.0000, Image 0.1126, Perp 0.4234, SSIM 0.3385 Total Loss 0.8746\n",
      "iter 40:\n",
      "Watermark 0.0000, Image 0.1122, Perp 0.4196, SSIM 0.3378 Total Loss 0.8696\n",
      "iter 41:\n",
      "Watermark 0.0000, Image 0.1117, Perp 0.4157, SSIM 0.3371 Total Loss 0.8646\n",
      "iter 42:\n",
      "Watermark 0.0000, Image 0.1114, Perp 0.4121, SSIM 0.3365 Total Loss 0.8600\n",
      "iter 43:\n",
      "Watermark 0.0000, Image 0.1110, Perp 0.4086, SSIM 0.3359 Total Loss 0.8555\n",
      "iter 44:\n",
      "Watermark 0.0000, Image 0.1106, Perp 0.4053, SSIM 0.3354 Total Loss 0.8513\n",
      "iter 45:\n",
      "Watermark 0.0000, Image 0.1103, Perp 0.4023, SSIM 0.3349 Total Loss 0.8474\n",
      "iter 46:\n",
      "Watermark 0.0000, Image 0.1100, Perp 0.3995, SSIM 0.3344 Total Loss 0.8438\n",
      "iter 47:\n",
      "Watermark 0.0000, Image 0.1097, Perp 0.3971, SSIM 0.3339 Total Loss 0.8407\n",
      "iter 48:\n",
      "Watermark 0.0000, Image 0.1095, Perp 0.3952, SSIM 0.3334 Total Loss 0.8382\n",
      "iter 49:\n",
      "Watermark 0.0000, Image 0.1093, Perp 0.3936, SSIM 0.3330 Total Loss 0.8359\n",
      "iter 50:\n",
      "Watermark 0.0000, Image 0.1092, Perp 0.3919, SSIM 0.3326 Total Loss 0.8337\n",
      "iter 51:\n",
      "Watermark 0.0000, Image 0.1091, Perp 0.3903, SSIM 0.3323 Total Loss 0.8317\n",
      "iter 52:\n",
      "Watermark 0.0000, Image 0.1091, Perp 0.3890, SSIM 0.3320 Total Loss 0.8300\n",
      "iter 53:\n",
      "Watermark 0.0000, Image 0.1090, Perp 0.3877, SSIM 0.3317 Total Loss 0.8284\n",
      "iter 54:\n",
      "Watermark 0.0000, Image 0.1091, Perp 0.3863, SSIM 0.3315 Total Loss 0.8269\n",
      "iter 55:\n",
      "Watermark 0.0000, Image 0.1091, Perp 0.3850, SSIM 0.3312 Total Loss 0.8253\n",
      "iter 56:\n",
      "Watermark 0.0000, Image 0.1091, Perp 0.3835, SSIM 0.3310 Total Loss 0.8237\n",
      "iter 57:\n",
      "Watermark 0.0000, Image 0.1092, Perp 0.3820, SSIM 0.3308 Total Loss 0.8219\n",
      "iter 58:\n",
      "Watermark 0.0000, Image 0.1092, Perp 0.3803, SSIM 0.3306 Total Loss 0.8201\n",
      "iter 59:\n",
      "Watermark 0.0000, Image 0.1093, Perp 0.3786, SSIM 0.3304 Total Loss 0.8182\n",
      "iter 60:\n",
      "Watermark 0.0000, Image 0.1093, Perp 0.3767, SSIM 0.3301 Total Loss 0.8162\n",
      "iter 61:\n",
      "Watermark 0.0000, Image 0.1093, Perp 0.3749, SSIM 0.3300 Total Loss 0.8142\n",
      "iter 62:\n",
      "Watermark 0.0000, Image 0.1094, Perp 0.3730, SSIM 0.3298 Total Loss 0.8122\n",
      "iter 63:\n",
      "Watermark 0.0000, Image 0.1094, Perp 0.3711, SSIM 0.3296 Total Loss 0.8101\n",
      "iter 64:\n",
      "Watermark 0.0000, Image 0.1094, Perp 0.3692, SSIM 0.3294 Total Loss 0.8081\n",
      "iter 65:\n",
      "Watermark 0.0000, Image 0.1094, Perp 0.3674, SSIM 0.3293 Total Loss 0.8062\n",
      "iter 66:\n",
      "Watermark 0.0000, Image 0.1095, Perp 0.3657, SSIM 0.3291 Total Loss 0.8043\n",
      "iter 67:\n",
      "Watermark 0.0000, Image 0.1095, Perp 0.3641, SSIM 0.3290 Total Loss 0.8026\n",
      "iter 68:\n",
      "Watermark 0.0000, Image 0.1095, Perp 0.3625, SSIM 0.3289 Total Loss 0.8010\n",
      "iter 69:\n"
     ]
    }
   ],
   "source": [
    "# Step 3: train the init latents\n",
    "for i in range(cfgs['iters']):\n",
    "    logging.info(f'iter {i}:')\n",
    "    init_latents_wm = wm_pipe.inject_watermark(init_latents)\n",
    "    if cfgs['empty_prompt']:\n",
    "        pred_img_tensor = pipe('', guidance_scale=1.0, num_inference_steps=50, output_type='tensor', use_trainable_latents=True, init_latents=init_latents_wm).images\n",
    "    else:\n",
    "        pred_img_tensor = pipe(prompt, num_inference_steps=50, output_type='tensor', use_trainable_latents=True, init_latents=init_latents_wm).images\n",
    "    loss = totalLoss(pred_img_tensor, gt_img_tensor, init_latents_wm, wm_pipe)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    loss_lst.append(loss.item())\n",
    "    # save watermarked image\n",
    "    if (i+1) in cfgs['save_iters']:\n",
    "        path = os.path.join(wm_path, f\"{imagename.split('.')[0]}_{i+1}.png\")\n",
    "        save_img(path, pred_img_tensor, pipe)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7564e5fd-d5a3-4de6-a979-f649a2ed0650",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Postprocessing with Adaptive Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54bb397-633d-49a1-bfda-72b45e5373f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter\n",
    "ssim_threshold = cfgs['ssim_threshold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ba93ce-f400-4290-bfb5-bde57c96b990",
   "metadata": {},
   "outputs": [],
   "source": [
    "wm_img_path = os.path.join(wm_path, f\"{imagename.split('.')[0]}_{cfgs['save_iters'][-1]}.png\")\n",
    "wm_img_tensor = get_img_tensor(wm_img_path, device)\n",
    "ssim_value = ssim(wm_img_tensor, gt_img_tensor).item()\n",
    "logging.info(f'Original SSIM {ssim_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43ec672-fa83-4b4a-9333-3d356798fced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search_theta(threshold, lower=0., upper=1., precision=1e-6, max_iter=1000):\n",
    "    for i in range(max_iter):\n",
    "        mid_theta = (lower + upper) / 2\n",
    "        img_tensor = (gt_img_tensor-wm_img_tensor)*mid_theta+wm_img_tensor\n",
    "        ssim_value = ssim(img_tensor, gt_img_tensor).item()\n",
    "\n",
    "        if ssim_value <= threshold:\n",
    "            lower = mid_theta\n",
    "        else:\n",
    "            upper = mid_theta\n",
    "        if upper - lower < precision:\n",
    "            break\n",
    "    return lower\n",
    "\n",
    "optimal_theta = binary_search_theta(ssim_threshold, precision=0.01)\n",
    "logging.info(f'Optimal Theta {optimal_theta}')\n",
    "\n",
    "img_tensor = (gt_img_tensor-wm_img_tensor)*optimal_theta+wm_img_tensor\n",
    "\n",
    "ssim_value = ssim(img_tensor, gt_img_tensor).item()\n",
    "psnr_value = compute_psnr(img_tensor, gt_img_tensor)\n",
    "\n",
    "tester_prompt = '' \n",
    "text_embeddings = pipe.get_text_embedding(tester_prompt)\n",
    "det_prob = 1 - watermark_prob(img_tensor, pipe, wm_pipe, text_embeddings)\n",
    "\n",
    "path = os.path.join(wm_path, f\"{os.path.basename(wm_img_path).split('.')[0]}_SSIM{ssim_threshold}.png\")\n",
    "save_img(path, img_tensor, pipe)\n",
    "logging.info(f'SSIM {ssim_value}, PSNR, {psnr_value}, Detect Prob: {det_prob} after postprocessing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b8b169-c1e9-437e-b3db-4a46887046a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Attack Watermarked Image with Individual Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7294ec83-97cc-4806-8404-a4fc07d83f81",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from main.wmattacker import *\n",
    "from main.attdiffusion import ReSDPipeline\n",
    "\n",
    "logging.info(f'===== Init Attackers =====')\n",
    "att_pipe = ReSDPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-1\", torch_dtype=torch.float16, revision=\"fp16\")\n",
    "att_pipe.set_progress_bar_config(disable=True)\n",
    "att_pipe.to(device)\n",
    "\n",
    "attackers = {\n",
    "    'diff_attacker_60': DiffWMAttacker(att_pipe, batch_size=5, noise_step=60, captions={}),\n",
    "    'cheng2020-anchor_3': VAEWMAttacker('cheng2020-anchor', quality=3, metric='mse', device=device),\n",
    "    'bmshj2018-factorized_3': VAEWMAttacker('bmshj2018-factorized', quality=3, metric='mse', device=device),\n",
    "    'jpeg_attacker_50': JPEGAttacker(quality=50),\n",
    "    'rotate_90': RotateAttacker(degree=90),\n",
    "    'brightness_0.5': BrightnessAttacker(brightness=0.5),\n",
    "    'contrast_0.5': ContrastAttacker(contrast=0.5),\n",
    "    'Gaussian_noise': GaussianNoiseAttacker(std=0.05),\n",
    "    'Gaussian_blur': GaussianBlurAttacker(kernel_size=5, sigma=1),\n",
    "    'bm3d': BM3DAttacker(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051f3d2d-6946-4806-b0d8-6363d15c8fec",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.info(f'===== Start Attacking... =====')\n",
    "\n",
    "post_img = os.path.join(wm_path, f\"{imagename.split('.')[0]}_{cfgs['save_iters'][-1]}_SSIM{ssim_threshold}.png\")\n",
    "for attacker_name, attacker in attackers.items():\n",
    "    print(f'Attacking with {attacker_name}')\n",
    "    os.makedirs(os.path.join(wm_path, attacker_name), exist_ok=True)\n",
    "    att_img_path = os.path.join(wm_path, attacker_name, os.path.basename(post_img))\n",
    "    attackers[attacker_name].attack([post_img], [att_img_path])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a2b6fa-6b19-4918-a141-8a5b9d112f0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Attack Watermarked Image with Combined Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5ddabd-1d5f-4541-acc2-d42c2e3c5487",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from main.wmattacker import *\n",
    "from main.attdiffusion import ReSDPipeline\n",
    "\n",
    "case_list = ['w/ rot', 'w/o rot']\n",
    "\n",
    "logging.info(f'===== Init Attackers =====')\n",
    "att_pipe = ReSDPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-1\", torch_dtype=torch.float16, revision=\"fp16\")\n",
    "att_pipe.set_progress_bar_config(disable=True)\n",
    "att_pipe.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb550932-cb3d-46fc-8174-c5ec2b69e447",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "post_img = os.path.join(wm_path, f\"{imagename.split('.')[0]}_{cfgs['save_iters'][-1]}_SSIM{ssim_threshold}.png\")\n",
    "\n",
    "for case in case_list:\n",
    "    print(f'Case: {case}')\n",
    "    if case == 'w/ rot':\n",
    "        attackers = {\n",
    "        'diff_attacker_60': DiffWMAttacker(att_pipe, batch_size=5, noise_step=60, captions={}),\n",
    "        'cheng2020-anchor_3': VAEWMAttacker('cheng2020-anchor', quality=3, metric='mse', device=device),\n",
    "        'bmshj2018-factorized_3': VAEWMAttacker('bmshj2018-factorized', quality=3, metric='mse', device=device),\n",
    "        'jpeg_attacker_50': JPEGAttacker(quality=50),\n",
    "        'rotate_90': RotateAttacker(degree=90),\n",
    "        'brightness_0.5': BrightnessAttacker(brightness=0.5),\n",
    "        'contrast_0.5': ContrastAttacker(contrast=0.5),\n",
    "        'Gaussian_noise': GaussianNoiseAttacker(std=0.05),\n",
    "        'Gaussian_blur': GaussianBlurAttacker(kernel_size=5, sigma=1),\n",
    "        'bm3d': BM3DAttacker(),\n",
    "        }\n",
    "        multi_name = 'all'\n",
    "    elif case == 'w/o rot':\n",
    "        attackers = {\n",
    "        'diff_attacker_60': DiffWMAttacker(att_pipe, batch_size=5, noise_step=60, captions={}),\n",
    "        'cheng2020-anchor_3': VAEWMAttacker('cheng2020-anchor', quality=3, metric='mse', device=device),\n",
    "        'bmshj2018-factorized_3': VAEWMAttacker('bmshj2018-factorized', quality=3, metric='mse', device=device),\n",
    "        'jpeg_attacker_50': JPEGAttacker(quality=50),\n",
    "        'brightness_0.5': BrightnessAttacker(brightness=0.5),\n",
    "        'contrast_0.5': ContrastAttacker(contrast=0.5),\n",
    "        'Gaussian_noise': GaussianNoiseAttacker(std=0.05),\n",
    "        'Gaussian_blur': GaussianBlurAttacker(kernel_size=5, sigma=1),\n",
    "        'bm3d': BM3DAttacker(),\n",
    "        }\n",
    "        multi_name = 'all_norot'\n",
    "        \n",
    "    \n",
    "    os.makedirs(os.path.join(wm_path, multi_name), exist_ok=True)\n",
    "    att_img_path = os.path.join(wm_path, multi_name, os.path.basename(post_img))\n",
    "    for i, (attacker_name, attacker) in enumerate(attackers.items()):\n",
    "        print(f'Attacking with {attacker_name}')\n",
    "        if i == 0:\n",
    "            attackers[attacker_name].attack([post_img], [att_img_path], multi=True)\n",
    "        else:\n",
    "            attackers[attacker_name].attack([att_img_path], [att_img_path], multi=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08da6ebe-ab6b-4ea0-9d55-006ace7bd4fd",
   "metadata": {},
   "source": [
    "## Detect Watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6064ad-8922-45f2-918d-8fc6157a5774",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_img = os.path.join(wm_path, f\"{imagename.split('.')[0]}_{cfgs['save_iters'][-1]}_SSIM{ssim_threshold}.png\")\n",
    "\n",
    "attackers = ['diff_attacker_60', 'cheng2020-anchor_3', 'bmshj2018-factorized_3', 'jpeg_attacker_50', \n",
    "             'brightness_0.5', 'contrast_0.5', 'Gaussian_noise', 'Gaussian_blur', 'rotate_90', 'bm3d', \n",
    "             'all', 'all_norot']\n",
    "\n",
    "tester_prompt = '' # assume at the detection time, the original prompt is unknown\n",
    "text_embeddings = pipe.get_text_embedding(tester_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4018ca81-ba9a-46d0-bad1-921132265b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f'===== Testing the Watermarked Images {post_img} =====')\n",
    "det_prob = 1 - watermark_prob(post_img, pipe, wm_pipe, text_embeddings)\n",
    "logging.info(f'Watermark Presence Prob.: {det_prob}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edeed73-b921-46b4-8bca-aeb436fdc843",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f'===== Testing the Attacked Watermarked Images =====')\n",
    "for attacker_name in attackers:\n",
    "    if not os.path.exists(os.path.join(wm_path, attacker_name)):\n",
    "        logging.info(f'Attacked images under {attacker_name} not exist.')\n",
    "        continue\n",
    "        \n",
    "    logging.info(f'=== Attacker Name: {attacker_name} ===')\n",
    "    det_prob = 1 - watermark_prob(os.path.join(wm_path, attacker_name, os.path.basename(post_img)), pipe, wm_pipe, text_embeddings)\n",
    "    logging.info(f'Watermark Presence Prob.: {det_prob}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unmarked",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
